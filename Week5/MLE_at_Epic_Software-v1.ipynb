{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"MLE_at_Epic_Software-v1.ipynb","provenance":[{"file_id":"1jKmDL0oebP9Wk5n7XskAaUS078RO1bJg","timestamp":1605836981047},{"file_id":"1WnkuqXCB55UtEe-1IrI7Pe88CJ5lSlQ2","timestamp":1605836760909}],"collapsed_sections":["dpMVM8vqtVFs"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FN-ViWqqtVFq"},"source":["# Today you are Machine Learning Engineer@ Epic Software Systems, and your task is to develop a new Recommendation System for the Opthalmologists (eye doctors)!\n","\n","### Diabetic Retinopathy (DR) is a pathology that impacts patients with Diabetes Mellitus 2, such that vision is compromised. Base paper on Automated classification of diabetic retinopathy:\n","https://ieeexplore.ieee.org/abstract/document/6680633\n","### Diabetic Retinopathy classification using modified AlexNet paper: https://www.sciencedirect.com/science/article/abs/pii/S0045790618334190\n","### Paper available at https://drive.google.com/file/d/1nl5tYA2jJ1Up_malA8uQmvwHu6UH0k-r/view?usp=sharing\n","\n","\n","### Automated classification of DR severity can help streamlie the treatment process such that patients with higher severity are seen by the doctor first followed by the less severe patiets. This problem of DR clasification is significant since retinal images are biometrics (unique for each individual) which makes generalized modeling difficult and since 90% of the diabetic population that get imaged each year are have NO DR.\n","\n","# Thus, the primary task is to automatically screen the patients that have NO DR (y=0), vs ones with mild DR (y=1), moderate DR (y=2) and severe DR (y=4). In this assignment you will develop such an automated system such that separates the normal images (y=0) from the non-zero ones (y=1,2,3)"]},{"cell_type":"markdown","metadata":{"id":"2yeDAkRJue6N"},"source":["### Mount your Google Drive"]},{"cell_type":"code","metadata":{"id":"fV8HKsvDuOi1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LO5Qps8pujZY"},"source":["### Change your working directory to the one containing this notebook"]},{"cell_type":"code","metadata":{"id":"DolSmooVupCf"},"source":["import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/Week 5 Live Assignment')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SIBgaZIbuVDn"},"source":["### Load TensorBoard and related libraries"]},{"cell_type":"code","metadata":{"id":"IpL2SLYLtVFq"},"source":["%load_ext tensorboard\n","from tensorflow import keras\n","import os\n","pwd = os.getcwd()\n","print(pwd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlN0YueOtVFr"},"source":["from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C10NEaomtVFr"},"source":["#Load the libraries\n","from datetime import datetime\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xopf7ZgKtVFr"},"source":["# Task 0: Get familiar with the data"]},{"cell_type":"code","metadata":{"id":"LEUW_jHmtVFr"},"source":["#Read the data and split into train and validation\n","from sklearn.model_selection import train_test_split\n","import h5py\n","f = h5py.File('1194_DR_smallimages.h5', 'r')\n","images = f['images']\n","labels = np.array(f['meta'])\n","print(f'Number of images = {len(labels)}')\n","#Plot the image and its label\n","num = 100\n","plt.imshow(images[num])\n","print(f\"This image has DR = {labels[num]}\")\n","print(f\"Maximum pixel value in image = {np.max(images[num])}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kdrGNQFhtVFs"},"source":["# Task 1: Data Pre-processing: \n","1. Exploratory data analysis (Frequency of labels)\n","2. Normalization of images in [0, 1] range.\n","3. Generation of Training, Test data sets (66/33% split)"]},{"cell_type":"markdown","metadata":{"id":"zhRr_V84v7p-"},"source":["### Exercise: Plot a histogram illustrating the number of images corresponding to each DR severity label"]},{"cell_type":"code","metadata":{"id":"rge9X3kwtVFs"},"source":["### START CODE HERE ###\n","None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TZfxdcWew9n5"},"source":["### Exercise: Normalize the images' pixel values so they fall in the range [0, 1]"]},{"cell_type":"code","metadata":{"id":"-MytDLxftVFs"},"source":["### START CODE HERE ###\n","images_new = None\n","### END CODE HERE ###\n","plt.imshow(images_new[10])\n","print(f\"Maximum pixel value in an image = {np.max(images_new[10])}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qbALXo5H0hcM"},"source":["### Exercise: Binarize the class labels. Set up 2 one-hot-encoded columns. Column 0 will contain a 1 for every row where the label is 0. Column 1 will contain a 1 for every row where the label is 1, 2, or 3.\n","\n","### You might be wondering why we don't use a single one-hot-encoded column, since our problem is binary classification. This will become clear in Task 2, when we inspect the AlexNet architecture. \n"]},{"cell_type":"code","metadata":{"id":"duDe7sk7skIw"},"source":["### START CODE HERE ###\n","# Initialize the one-hot-encoded array of labels as 2 columns of zeros\n","one_hot_labels = None\n","# Find the rows where the label is 0\n","lab0 = None\n","# Find the rows where the label is 1, 2, or 3\n","lab1 = None\n","# Set column 0 to 1 in the rows where the label is 0\n","one_hot_labels[None, None] = None\n","# Set column 1 to 1 in the rows where the label is 1, 2, or 3\n","one_hot_labels[None, None] = None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0eUvLD1JN_Bu"},"source":["### Exercise: Perform a 2/3 - 1/3 train-test split on the data"]},{"cell_type":"code","metadata":{"id":"Jty-CUI0Phiz"},"source":["### START CODE HERE ###\n","def split_data(mat, target, train_ratio):\n","    # Get the number of rows in the training data\n","    train_rows = None\n","    # Place the first `train_rows` shuffled rows into the training data \n","    # and the remaining rows into the test data\n","    X_train = None\n","    X_test  = None\n","    Y_train = None\n","    Y_test  = None\n","    return X_train, X_test, Y_train, Y_test\n","\n","# Call the function you just defined to create the training and test data\n","X_train, X_test, Y_train, Y_test = None\n","\n","### END CODE HERE ###\n","# Visualize the distribution of the binarized labels for both the training and test data\n","plt.hist(Y_train[:,1])\n","plt.hist(Y_test[:,1])\n","print(f'X_train.shape = {X_train.shape}')\n","print(f'X_test.shape  = {X_test.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"usiNL9SotVFs"},"source":["# Task 2: Model Definition, classification and prediction (No regularization)"]},{"cell_type":"markdown","metadata":{"id":"wSGjpe54efCN"},"source":["## AlexNet architecture"]},{"cell_type":"code","metadata":{"id":"5fGMFAqCtVFs"},"source":["# Define the AlexNet model [This is given]\n","#1. Model Definition\n","class AlexNet(Sequential):\n","   def __init__(self, input_shape, num_classes):\n","    super().__init__()\n","\n","    self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n","                    padding= 'valid', activation= 'relu',\n","                    input_shape= input_shape, kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n","                          padding= 'valid', data_format= None))\n","    \n","    \n","    self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n","                          padding= 'valid', data_format= None)) \n","    \n","\n","    self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    \n","    self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    \n","    self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n","                    padding= 'same', activation= 'relu',\n","                    kernel_initializer= 'he_normal'))\n","    self.add(BatchNormalization())\n","    \n","    self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n","                          padding= 'valid', data_format= None))\n","    \n","\n","    self.add(Flatten())\n","    \n","    self.add(Dense(num_classes, activation= 'softmax'))\n","\n","    self.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"txc7-3WxoIic"},"source":["### Since our problem involves binary classification, set `num_classes` to 2"]},{"cell_type":"code","metadata":{"id":"ngTskMERtVFs"},"source":["num_classes = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1pMxmDuPl2lM"},"source":["### Exercise: Instantiate the model and summarize its architecture"]},{"cell_type":"code","metadata":{"id":"NeGeg_LQtVFs"},"source":["### START CODE HERE ###\n","model = None\n","None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGAE8oJJp6Vf"},"source":["### Exercise: Train the model. If you want to use TensorBoard to visualize how its properties evolve over the training epochs, you'll have to create a log directory and employ a TensorBoard callback. If you'd like, you can implement them in v1 of this notebook, but it's not required. v2 will include them, however.\n","### In training the model, set aside 20% of the data as a validation set. Use a batch size of 100. Set the output verbosity to 1. Train the model for 40 epochs."]},{"cell_type":"code","metadata":{"id":"3ipP4sartVFs"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from helper_functions import *\n","\n","### START CODE HERE ###\n","training_history = None\n","### END CODE HERE ###\n","\n","print(\"Average test loss: \", np.average(training_history.history['loss']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"virBzWKumZ3l"},"source":["### Exercise: Display loss and accuracy for both the training and validation data. You should find the provided functions in `helper_functions.py` useful. "]},{"cell_type":"code","metadata":{"id":"pHk5rvpitVFs"},"source":["### START CODE HERE ###\n","None\n","None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eJqZxyJwBlol"},"source":["### Exercise: Generate predictions with the test data"]},{"cell_type":"code","metadata":{"id":"tKm9CzwvtVFs"},"source":["### START CODE HERE ###\n","prediction_values = None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cpO3gXbfCH8F"},"source":["### Exercise: Evaluate the predictions against the Number 1 column of `Y_test`"]},{"cell_type":"code","metadata":{"id":"DYE3vbX0tVFs"},"source":["### START CODE HERE ###\n","# Import the necessary functions from sklearn.metrics\n","from sklearn.metrics import None\n","print(f'Accuracy = {None}')\n","print(f'F1 = {None}')\n","print(f'Precision = {None}')\n","print(f'Recall = {None}')\n","# Display the confusion matrix\n","print('Confusion matrix =')\n","None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dpMVM8vqtVFs"},"source":["### Next, visualize the activations.\n","Source: https://www.kaggle.com/amarjeet007/visualize-cnn-with-keras"]},{"cell_type":"markdown","metadata":{"id":"aYavRekWIoOF"},"source":["### Exercise: Extract the activations for each layer in our AlexNet model"]},{"cell_type":"code","metadata":{"id":"X0pZ_NFHtVFs"},"source":["### START CODE HERE ###\n","# Use a list comprehension to extract the output of each layer in the model\n","layer_outputs = None\n","# Define a new model with the same input shape as the original model \n","# and layer_outputs as its outputs\n","activation_model = None\n","# Get all the activations by calling the predict() method on the number 10 image \n","# in X_train. Make sure to reshape the image so it has a new 0 axis of length 1.\n","activations = None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kTLUUg8FNNqW"},"source":["### Exercise: Display the first 64 activations of the second model layer (layer index 1) in an 8 x 8 grid. Again, the helper functions are your friends."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"1xvbj75GtVFs"},"source":["### START CODE HERE ###\n","None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2MHYr_JQPvp"},"source":["### Exercise: Display the first 64 activations of the 11th model layer (layer index 10) in an 8 x 8 grid"]},{"cell_type":"code","metadata":{"id":"y161bAR_tVFs"},"source":["### START CODE HERE ###\n","None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5gkWuOb9tVFs"},"source":["# Comment on the activated feature maps for early layers to later layers. What pattern do you observe?"]},{"cell_type":"markdown","metadata":{"id":"rYBVyTXYtVFt"},"source":["# Task 3: Regularization by Data Augmentation [Instructor Led]"]},{"cell_type":"markdown","metadata":{"id":"3Ha5ruYFQ0nC"},"source":["## We can regularize our model (and, in doing so, hopefully improve it) by augmenting our image data. Image augmentation includes transformations such as rotation, translation, reflection, shearing, and color permutation. TensorFlow provides the ImageDataGenerator class to perform image augmentation in memory; by default, your local storage won't save the newly generated images."]},{"cell_type":"code","metadata":{"id":"QRofVa3mtVFt"},"source":["# Create a Data Generator\n","data_gen_args = dict( \n","    rotation_range=10.,\n","    width_shift_range=0.05,\n","    height_shift_range=0.05,\n","    zoom_range=0.2,\n","    channel_shift_range=0.05,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='constant',\n","    data_format=\"channels_last\",\n",")\n","image_datagen = ImageDataGenerator(**data_gen_args)\n","\n","image_datagen.fit(X_train)\n","BATCH_SIZE = X_train.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRplxbhDRHb2"},"source":["### Initialize data generator for training/validation and test data sets"]},{"cell_type":"code","metadata":{"id":"WlloVtHqtVFt"},"source":["train_generator = image_datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE)\n","test_generator = image_datagen.flow(X_test, Y_test, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-vyWwv2RQzX"},"source":["### Import libraries and set useful parameters"]},{"cell_type":"code","metadata":{"id":"vp3034wqtVFt"},"source":["import h5py\n","from tensorflow.keras.utils import HDF5Matrix\n","seed = 0\n","aug_batch_size = 6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kmJ9PThctVFt"},"source":["## Step 1: Understanding the data augmentation process\n","Images are randomly generated with the options provided in the image data generator"]},{"cell_type":"code","metadata":{"id":"-lHj0f0RtVFt"},"source":["for e in range(5):\n","    print('Epoch', e)\n","    batches = 0\n","    for x_batch, y_batch in image_datagen.flow(X_train, Y_train, batch_size=aug_batch_size):\n","        print(x_batch.shape)\n","        for i in range(0, aug_batch_size):\n","            plt.subplot(330+1 + i)\n","            plt.imshow(x_batch[i], cmap=plt.get_cmap('gray'))\n","        \n","\n","        plt.show()\n","        print(y_batch)\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJGi7-LDtVFt"},"source":["## Step 2: Using augmented data to Train the model\n","### Visualize using tensorboard"]},{"cell_type":"markdown","metadata":{"id":"SXcTSbcmTgCi"},"source":["### Method 1: Iterate through randomized `(X, y)` batches generated by `train_generator` and fit AlexNet to each one"]},{"cell_type":"code","metadata":{"id":"aB8EwEUOtVFt"},"source":["model_reg = AlexNet((np.shape(X_train)[1],np.shape(X_train)[2], 3), num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8o2IfhXtVFt"},"source":["#Method 1: Randomized batches\n","EPOCHS = 50\n","reg_history_loss = []\n","reg_history_vloss = []\n","reg_history_accuracy = []\n","reg_history_val_accuracy = []\n","# Start training\n","for e in range(EPOCHS):\n","    print('Epoch', e)\n","    batches = 0\n","    for x_batch, y_batch in train_generator:\n","        reg_hist = (model_reg.fit(x_batch, y_batch,validation_split=0.2, verbose=1))\n","        batches += 1\n","        reg_history_loss.append(reg_hist.history['loss'])\n","        reg_history_vloss.append(reg_hist.history['val_loss'])\n","        reg_history_accuracy.append(reg_hist.history['accuracy'])\n","        reg_history_val_accuracy.append(reg_hist.history['val_accuracy'])\n","        if batches >= len(X_train) / BATCH_SIZE:\n","            # we need to break the loop by hand because\n","            # the generator loops indefinitely\n","            break  \n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ajwUrwDwSy5D"},"source":["### Plot the losses and accuracies for both training and validation data"]},{"cell_type":"code","metadata":{"id":"S5fiVcXrtVFt"},"source":["#Print the loss and accuracies\n","#print_loss_history(reg_history)\n","t_loss = np.squeeze(np.array(reg_history_loss))\n","v_loss = np.squeeze(np.array(reg_history_vloss))\n","t_acc  = np.squeeze(np.array(reg_history_accuracy))\n","v_acc  = np.squeeze(np.array(reg_history_val_accuracy))\n","print(len(t_loss))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-ON4fZWS94W"},"source":["### Loss"]},{"cell_type":"code","metadata":{"id":"m332hNUqtVFt"},"source":["epochs = range(len(t_loss))\n","plt.plot(epochs, t_loss, color='red', label='Training loss')\n","plt.plot(epochs, v_loss, color='green', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AOX7HtKvS_9a"},"source":["### Accuracy"]},{"cell_type":"code","metadata":{"id":"mh7vwbxetVFt"},"source":["epochs=range(len(t_acc))\n","plt.plot(epochs, t_acc, color='red', label='Training Accuracy')\n","plt.plot(epochs, v_acc, color='green', label='Validation Accuracy')\n","plt.title('Training and validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QCZuZWLQTKGL"},"source":["### Method 2: Pass `train_generator` into the model's `fit()` method directly and abstract away the looping"]},{"cell_type":"code","metadata":{"id":"AVqL13L8tVFt"},"source":["#Method 2\n","model_reg_2 = AlexNet((np.shape(X_train)[1],np.shape(X_train)[2], 3), num_classes)\n","reg_history = model_reg_2.fit(\n","    train_generator,\n","    steps_per_epoch=50,\n","    verbose=1, \n","    epochs=40,\n","#    callbacks=[tensorboard_callback]\n",")\n","\n","print(\"Average test loss: \", np.average(reg_history.history['loss']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_lZqgKrtVFt"},"source":["# save the whole model\n","model_reg_2_dir = \"reg_model.h5\"\n","model_reg_2.save(model_reg_2_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"JwnAFvlLtVFt"},"source":["%tensorboard --logdir logs/scalars"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZCIxpNPitVFt"},"source":["# Task 4: Evaluate the Regularized Model and Report Results"]},{"cell_type":"markdown","metadata":{"id":"VEUFudHjUTtg"},"source":["### Exercise: Compute the evaluation metrics"]},{"cell_type":"code","metadata":{"id":"qVzPv2u3tVFt"},"source":["### START CODE HERE ###\n","prediction_reg = None\n","print(f'Accuracy = {None}')\n","print(f'F1 = {None}')\n","print(f'Precision = {None}')\n","print(f'Recall = {None}')\n","print('Confusion matrix = ')\n","None\n","### END CODE HERE ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8vKsAAJ2tVFt"},"source":["# Visualize activations from early layers after regularization and report results"]},{"cell_type":"code","metadata":{"id":"zxevfDmptVFt"},"source":[""],"execution_count":null,"outputs":[]}]}