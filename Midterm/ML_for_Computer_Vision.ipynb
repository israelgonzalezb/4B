{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This assignment is designed for automated pathology detection for Medical Images in a realistic setup, i.e. each image may have multiple pathologies/disorders. \n",
    "### The goal, for you as an MLE, is to design models and methods to predictively detect pathological images and explain the pathology sites in the image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for this assignment is taken from a Kaggle contest: https://www.kaggle.com/c/vietai-advance-course-retinal-disease-detection/overview\n",
    "Explanation of the data set:\n",
    "The training data set contains 3435 retinal images that represent multiple pathological disorders. The patholgy classes and corresponding labels are: included in 'train.csv' file and each image can have more than one class category (multiple pathologies).\n",
    "The labels for each image are\n",
    "\n",
    "```\n",
    "-opacity (0), \n",
    "-diabetic retinopathy (1), \n",
    "-glaucoma (2),\n",
    "-macular edema (3),\n",
    "-macular degeneration (4),\n",
    "-retinal vascular occlusion (5)\n",
    "-normal (6)\n",
    "```\n",
    "The test data set contains 350 unlabelled images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For this assignment, you are working with specialists for Diabetic Retinopathy and Glaucoma only, and your client is interested in a predictive learning model along with feature explanability and self-learning for Diabetic Retinopathy and Glaucoma vs. Normal images.\n",
    "# Design models and methods for the following tasks. Each task should be accompanied by code, plots/images (if applicable), tables (if applicable) and text:\n",
    "## Task 1: Build a classification model for Diabetic Retinopathy and Glaucoma vs normal images. You may consider multi-class classification vs. all-vs-one classification. Clearly state your choice and share details of your model, parameters and hyper-paramaterization process. (60 points)\n",
    "```\n",
    "a. Perform 70/30 data split and report performance scores on the test data set.\n",
    "b. You can choose to apply any data augmentation strategy. \n",
    "Explain your methods and rationale behind parameter selection.\n",
    "c. Show Training-validation curves to ensure overfitting and underfitting is avoided.\n",
    "```\n",
    "## Task 2: Visualize the heatmap/saliency/features using any method of your choice to demonstrate what regions of interest contribute to Diabetic Retinopathy and Glaucoma, respectively. (25 points)\n",
    "```\n",
    "Submit images/folder of images with heatmaps/features aligned on top of the images, or corresponding bounding boxes, and report what regions of interest in your opinion represent the pathological sites.\n",
    "```\n",
    "\n",
    "## Task 3: Using the unlabelled data set in the 'test' folder augment the training data (semi-supervised learning) and report the variation in classification performance on test data set.(15 points)\n",
    "[You may use any method of your choice, one possible way is mentioned below.] \n",
    "\n",
    "```\n",
    "Hint: \n",
    "a. Train a model using the 'train' split.\n",
    "b. Pass the unlabelled images through the trained model and retrieve the dense layer feature prior to classification layer. Using this dense layer as representative of the image, apply label propagation to retrieve labels correspndng to the unbalelled data.\n",
    "c. Next, concatenate the train data with the unlabelled data (that has now been self labelled) and retrain the network.\n",
    "d. Report classification performance on test data\n",
    "Use the unlabelled test data  to improve classification performance by using a semi-supervised label-propagation/self-labelling approach. (20 points)\n",
    "```\n",
    "## Good Luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and reset data to original for \n",
    "# re-running the notebook from the start\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "path = './Data/train/validation'\n",
    "files = os.listdir('./Data/train/validation')\n",
    "for file in files:\n",
    "    file = os.path.join(path, file)\n",
    "    shutil.move(file, './Data/train/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opacity</th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>macular edema</th>\n",
       "      <th>macular degeneration</th>\n",
       "      <th>retinal vascular occlusion</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c24a1b14d253.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ee905a41651.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f58d128caf6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ce6599e7b20.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0def470360e4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  opacity  diabetic retinopathy  glaucoma  macular edema  \\\n",
       "0  c24a1b14d253.jpg        0                     0         0              0   \n",
       "1  9ee905a41651.jpg        0                     0         0              0   \n",
       "2  3f58d128caf6.jpg        0                     0         1              0   \n",
       "3  4ce6599e7b20.jpg        1                     0         0              0   \n",
       "4  0def470360e4.jpg        1                     0         0              0   \n",
       "\n",
       "   macular degeneration  retinal vascular occlusion  normal  \n",
       "0                     0                           1       0  \n",
       "1                     0                           1       0  \n",
       "2                     0                           0       0  \n",
       "3                     1                           0       0  \n",
       "4                     1                           0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# bring in training csv\n",
    "train_csv = pd.read_csv('./Data/train/train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3435, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3435, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns we aren't using\n",
    "train_csv = train_csv.drop(labels=['opacity', 'macular edema',\n",
    "                                   'macular degeneration',\n",
    "                                   'retinal vascular occlusion'],\n",
    "                           axis='columns')\n",
    "train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c24a1b14d253.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ee905a41651.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f58d128caf6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ce6599e7b20.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0def470360e4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  diabetic retinopathy  glaucoma  normal\n",
       "0  c24a1b14d253.jpg                     0         0       0\n",
       "1  9ee905a41651.jpg                     0         0       0\n",
       "2  3f58d128caf6.jpg                     0         1       0\n",
       "3  4ce6599e7b20.jpg                     0         0       0\n",
       "4  0def470360e4.jpg                     0         0       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>normal</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c24a1b14d253.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ee905a41651.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f58d128caf6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ce6599e7b20.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0def470360e4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  diabetic retinopathy  glaucoma  normal  other\n",
       "0  c24a1b14d253.jpg                     0         0       0      1\n",
       "1  9ee905a41651.jpg                     0         0       0      1\n",
       "2  3f58d128caf6.jpg                     0         1       0      0\n",
       "3  4ce6599e7b20.jpg                     0         0       0      1\n",
       "4  0def470360e4.jpg                     0         0       0      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!!! TODO: Determine what to do with images that belong to no category\n",
    "conditions = [\n",
    "    (train_csv['diabetic retinopathy'] == 1),\n",
    "    (train_csv['diabetic retinopathy'] == 1),\n",
    "    (train_csv['diabetic retinopathy'] == 1),\n",
    "    (train_csv['diabetic retinopathy'] == 0) \n",
    "    & (train_csv['glaucoma'] == 0)\n",
    "    & (train_csv['normal'] == 0),\n",
    "]\n",
    "values = [0, 0, 0, 1]\n",
    "train_csv['other'] = np.select(conditions, values)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>normal</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f58d128caf6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10ee8c8a72b4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3b6da0297f92.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>677c30357c4e.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>90ff4cbcdc9b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  diabetic retinopathy  glaucoma  normal  other\n",
       "2   3f58d128caf6.jpg                     0         1       0      0\n",
       "18  10ee8c8a72b4.jpg                     1         0       0      0\n",
       "19  3b6da0297f92.jpg                     1         0       0      0\n",
       "20  677c30357c4e.jpg                     1         0       0      0\n",
       "23  90ff4cbcdc9b.jpg                     1         0       0      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './Data/train/train/'\n",
    "other_path = './Data/train/train/Other'\n",
    "other_indices = []\n",
    "for index, row in train_csv.iterrows():\n",
    "    if row['other'] == 1:\n",
    "        other_indices.append(index)\n",
    "        file = os.path.join(train_path+row['filename'])\n",
    "        shutil.move(file, other_path)\n",
    "train_csv = train_csv.drop(index=other_indices)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1858, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = train_csv.drop(columns='other', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1858, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1858, 4)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "train_csv = train_csv.sample(frac=1)\n",
    "print(train_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs and data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1858.000000</td>\n",
       "      <td>1858.000000</td>\n",
       "      <td>1858.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.406351</td>\n",
       "      <td>0.321313</td>\n",
       "      <td>0.282562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491284</td>\n",
       "      <td>0.467106</td>\n",
       "      <td>0.450366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       diabetic retinopathy     glaucoma       normal\n",
       "count           1858.000000  1858.000000  1858.000000\n",
       "mean               0.406351     0.321313     0.282562\n",
       "std                0.491284     0.467106     0.450366\n",
       "min                0.000000     0.000000     0.000000\n",
       "25%                0.000000     0.000000     0.000000\n",
       "50%                0.000000     0.000000     0.000000\n",
       "75%                1.000000     1.000000     1.000000\n",
       "max                1.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'diabetic retinopathy'}>,\n",
       "        <AxesSubplot:title={'center':'glaucoma'}>],\n",
       "       [<AxesSubplot:title={'center':'normal'}>, <AxesSubplot:>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "test_portion = math.floor(.3 * train_csv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = train_csv[0:test_portion]\n",
    "test_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>a610568289dc.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>bfc3bb24c630.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>f296dbe7fd0a.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>2eeb0c7908c5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>02bff9fd3750.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  diabetic retinopathy  glaucoma  normal\n",
       "2477  a610568289dc.jpg                     1         0       0\n",
       "638   bfc3bb24c630.jpg                     0         1       0\n",
       "36    f296dbe7fd0a.jpg                     1         0       0\n",
       "3231  2eeb0c7908c5.jpg                     0         0       1\n",
       "2849  02bff9fd3750.jpg                     1         0       0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1301, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = train_csv[test_portion:]\n",
    "train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files = os.listdir('./Data/train/train/')\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = test_csv['filename']\n",
    "for file in validation_images:\n",
    "    file = os.path.join('./Data/train/train', file)\n",
    "    #print(file)\n",
    "    shutil.move(file, '/home/sarah/FourthBrain/Midterm/Data/train/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras import backend as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=0.2,\n",
    "                                                 width_shift_range=0.05,\n",
    "                                                 height_shift_range=0.05,\n",
    "                                                 zoom_range=[0.7,1],\n",
    "                                                 horizontal_flip=True,\n",
    "                                                 vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from Week 7 assignment\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = keras.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = keras.sum(y_true, axis=[1,2,3]) + keras.sum(y_pred, axis=[1,2,3])\n",
    "    return keras.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 16\n",
    "def vgg16(pretrained_weights=None, input_size=(224, 224, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, 1, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(512, 1, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    flat = Flatten()(x)\n",
    "    dense = Dense(1*1*512, activation='relu')(flat)\n",
    "    dropout = Dropout(0.5)(dense)\n",
    "    \n",
    "    dense_last = Dense(4096, activation='relu')(dense)\n",
    "    #dropout = Dropout(0.5)(dense)\n",
    "    \n",
    "    soft = Dense(4, activation='softmax')(dense_last)\n",
    "    \n",
    "    #soft = Softmax()(dense_last)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=soft)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-6), loss='categorical_crossentropy', metrics='accuracy')\n",
    "    \n",
    "    if (pretrained_weights):\n",
    "        model=keras.models.load_model(pretrained_weights)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 25,483,588\n",
      "Trainable params: 25,483,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "%load_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1301 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1079, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 923, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 659, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 363, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/lib/python3.9/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 250, in wrapper\n",
      "    runner = Runner(ctx_run, result, future, yielded)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 741, in __init__\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-7518e5277d11>\", line 3, in <module>\n",
      "    train_gen = datagen.flow_from_dataframe(directory = './Data/train/train',\n",
      "  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py\", line 1070, in flow_from_dataframe\n",
      "    tf_logging.warn(\n",
      "  File \"/usr/lib/python3.9/site-packages/tensorflow/python/platform/tf_logging.py\", line 173, in warn\n",
      "    get_logger().warning(msg, *args, **kwargs)\n",
      "Message: '`class_mode` \"other\" is deprecated, please use `class_mode` \"raw\".'\n",
      "Arguments: (<class 'DeprecationWarning'>,)\n"
     ]
    }
   ],
   "source": [
    "#columns = ['diabetic retinopathy', 'glaucoma', 'normal', 'other']\n",
    "columns = ['diabetic retinopathy', 'glaucoma', 'normal']\n",
    "train_gen = datagen.flow_from_dataframe(directory = './Data/train/train',\n",
    "                                        dataframe = train_csv,\n",
    "                                        x_col = 'filename',\n",
    "                                        y_col = columns,\n",
    "                                        target_size=(224,224),\n",
    "                                        batch_size=15,\n",
    "                                        rescale=1./255,\n",
    "                                        class_mode='other',\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1079, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 923, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 659, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 363, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/lib/python3.9/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 250, in wrapper\n",
      "    runner = Runner(ctx_run, result, future, yielded)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 741, in __init__\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/usr/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-e27d0df1f43a>\", line 8, in <module>\n",
      "    test_gen = datagen.flow_from_dataframe(directory = './Data/train/validation/',\n",
      "  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py\", line 1070, in flow_from_dataframe\n",
      "    tf_logging.warn(\n",
      "  File \"/usr/lib/python3.9/site-packages/tensorflow/python/platform/tf_logging.py\", line 173, in warn\n",
      "    get_logger().warning(msg, *args, **kwargs)\n",
      "Message: '`class_mode` \"other\" is deprecated, please use `class_mode` \"raw\".'\n",
      "Arguments: (<class 'DeprecationWarning'>,)\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=0,\n",
    "                                                 width_shift_range=0.0,\n",
    "                                                 height_shift_range=0.0,\n",
    "                                                 horizontal_flip=False,\n",
    "                                                 vertical_flip=False)\n",
    "#columns = ['diabetic retinopathy', 'glaucoma', 'normal', 'other']\n",
    "columns = ['diabetic retinopathy', 'glaucoma', 'normal']\n",
    "test_gen = datagen.flow_from_dataframe(directory = './Data/train/validation/',\n",
    "                                        dataframe = test_csv,\n",
    "                                        x_col = 'filename',\n",
    "                                        y_col = columns,\n",
    "                                        target_size=(224,224),\n",
    "                                        batch_size=10,\n",
    "                                        rescale=1./255,\n",
    "                                        class_mode='other',\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[15,4] labels_size=[15,3]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at <ipython-input-30-4bf58f0801ec>:6) ]] [Op:__inference_train_function_1770]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4bf58f0801ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m fitting = model.fit_generator(train_gen,\n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1847\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[15,4] labels_size=[15,3]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at <ipython-input-30-4bf58f0801ec>:6) ]] [Op:__inference_train_function_1770]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "now = str(time.time())\n",
    "checkpoint = now + 'vgg16.hdf5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor='loss',verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "fitting = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=100,\n",
    "                    verbose=1, \n",
    "                    validation_data=test_gen,\n",
    "                    validation_steps = 10,\n",
    "                    callbacks=[tensorboard_callback, model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fitting.history['accuracy'])\n",
    "plt.plot(fitting.history['val_accuracy'])\n",
    "plt.plot(fitting.history['loss'])\n",
    "plt.plot(fitting.history['val_loss'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Accuracy', 'Validation Accuracy', 'Loss', 'Validation Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_number(df):\n",
    "    numbers = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['diabetic retinopathy'] ==1:\n",
    "            numbers.append(0)\n",
    "        elif row['glaucoma'] == 1:\n",
    "            numbers.append(1)\n",
    "        elif row['normal'] == 1:\n",
    "            numbers.append(2)\n",
    "        elif row['other'] == 1:\n",
    "            numbers.append(3)\n",
    "        else:\n",
    "            print('PROBLEM')\n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_val = class_to_number(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "target_names = ['diabetic retinopathy', 'glaucoma', 'normal', 'other']\n",
    "print(confusion_matrix(y_true_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task was heavily influenced by an example from the library [tf-keras-vis](https://github.com/keisen/tf-keras-vis/blob/master/examples/attentions.ipynb).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras-vis\n",
    "import tf_keras_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "stuff = ['883d583c0f29.jpg', 'e8f1075cd1e3.jpg', '7fbdc707365e.jpg']\n",
    "titles = ['diabetic retinopathy', 'glaucoma', 'normal']\n",
    "path = '/home/sarah/FourthBrain/Midterm/Data/train/validation/'\n",
    "\n",
    "img1 = load_img(path+stuff[0], target_size=(224,224))\n",
    "img2 = load_img(path+stuff[1], target_size=(224,224))\n",
    "img3 = load_img(path+stuff[2], target_size=(224,224))\n",
    "images = np.asarray([np.array(img1), np.array(img2), np.array(img3)])\n",
    "\n",
    "X = preprocess_input(images)\n",
    "\n",
    "subplot_args = {'nrows': 1,\n",
    "               'ncols': 3,\n",
    "               'figsize': (9,3),\n",
    "               }\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "for i in range(3):\n",
    "    ax[i].set_title(titles[i], fontsize=14)\n",
    "    ax[i].imshow(images[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Saliency\n",
    "\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils import normalize\n",
    "\n",
    "def model_modifier(m):\n",
    "    m.layers[-1].activation = tf.keras.activations.linear\n",
    "    return m\n",
    "\n",
    "# Output of model\n",
    "def loss(output):\n",
    "    return (output[0][1], output[1][2], output[2][3])\n",
    "\n",
    "saliency = Saliency(model,\n",
    "                   model_modifier=model_modifier,\n",
    "                   clone=False)\n",
    "\n",
    "saliency_map = saliency(loss, X)\n",
    "saliency_map = normalize(saliency_map)\n",
    "\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "for i in range(3):\n",
    "    ax[i].set_title(titles[i], fontsize=14)\n",
    "    ax[i].imshow(images[i])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "for i in range(3):\n",
    "    ax[i].set_title(titles[i], fontsize=14)\n",
    "    ax[i].imshow(saliency_map[i], cmap='jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth Grad\n",
    "\n",
    "saliency_map = saliency(loss,\n",
    "                       X,\n",
    "                       smooth_samples=20,\n",
    "                       smooth_noise=0.20)\n",
    "saliency_map = normalize(saliency_map)\n",
    "\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "for i in range(3):\n",
    "    ax[i].set_title(titles[i], fontsize=14)\n",
    "    ax[i].imshow(images[i])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "for i in range(3):\n",
    "    ax[i].set_title(titles[i], fontsize=14)\n",
    "    ax[i].imshow(saliency_map[i], cmap='jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad Cam\n",
    "\n",
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "\n",
    "gradcam = Gradcam(model,\n",
    "                 model_modifier=model_modifier,\n",
    "                 clone=False)\n",
    "cam = gradcam(loss,\n",
    "             X,\n",
    "             penultimate_layer=-1)\n",
    "cam = normalize(cam)\n",
    "\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "for i in range(3):\n",
    "    ax[i].set_title(titles[i], fontsize=14)\n",
    "    ax[i].imshow(images[i])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "f, ax = plt.subplots(**subplot_args)\n",
    "for i in range(3):\n",
    "    ax[i].set_title(titles[i], fontsize=14)\n",
    "    ax[i].imshow(images[i])\n",
    "    ax[i].imshow(saliency_map[i], cmap='jet')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model is not really well trained enough to get good answers for being able to understand the features the model is focusing on to make the classification of retinal images, however, based on the images and saliency maps I was able to create, I will try to make some observations.  \n",
    "In diabetic retinopathy the attention of the model seems to be focused on the brighter flashy spots on the image.  \n",
    "For glaucoma, the attention seems to be focused on the area immediately surrounding the optic disk, but not the disk itself.  \n",
    "In normal retinal images, the attention seems to be on the edges and completely ignoring the macula and the optic disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint:   \n",
    "a. Train a model using the 'train' split.  \n",
    "b. Pass the unlabelled images through the trained model and retrieve the dense layer feature prior to classification layer. Using this dense layer as representative of the image, apply label propagation to retrieve labels correspondng to the unbalelled data.  \n",
    "c. Next, concatenate the train data with the unlabelled data (that has now been self labelled) and retrain the network.  \n",
    "d. Report classification performance on test data  \n",
    "Use the unlabelled test data  to improve classification performance by using a semi-supervised label-propagation/self-labelling approach. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=0,\n",
    "                                                 width_shift_range=0.0,\n",
    "                                                 height_shift_range=0.0,\n",
    "                                                 horizontal_flip=False,\n",
    "                                                 vertical_flip=False)\n",
    "columns = ['diabetic retinopathy', 'glaucoma', 'normal', 'other']\n",
    "unlabeled_gen = datagen.flow_from_directory(directory = './Data/test/', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'dense_1'\n",
    "intermediate_model = Model(inputs=model.input,\n",
    "                           outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_model.predict(unlabeled_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intermediate_output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_head(input_size=(4096,)):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    soft = Dense(4, activation='softmax')(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=soft)\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics='accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationHead = classification_head()\n",
    "classificationHead.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_probabilities = classificationHead.predict(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlabeled_gen\n",
    "#\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels = kmeans.fit_predict(pseudo_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pseudo_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pseudo_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pseudo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_class(labels, images):\n",
    "    images = images\n",
    "    dr = []\n",
    "    glaucoma = []\n",
    "    normal = []\n",
    "    other = []\n",
    "    for number in labels:\n",
    "        if number == 0:\n",
    "            dr.append(1)\n",
    "            glaucoma.append(0)\n",
    "            normal.append(0)\n",
    "            other.append(0)\n",
    "        elif number == 1:\n",
    "            dr.append(0)\n",
    "            glaucoma.append(1)\n",
    "            normal.append(0)\n",
    "            other.append(0)\n",
    "        elif number == 2:\n",
    "            dr.append(0)\n",
    "            glaucoma.append(0)\n",
    "            normal.append(1)\n",
    "            other.append(0)\n",
    "        elif number == 3:\n",
    "            dr.append(0)\n",
    "            glaucoma.append(0)\n",
    "            normal.append(0)\n",
    "            other.append(1)\n",
    "    df = pd.DataFrame(data={'filename': images,\n",
    "                            'diabetic retinopath': dr,\n",
    "                            'glaucoma': glaucoma,\n",
    "                            'normal': normal,\n",
    "                            'other': other})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir('/home/sarah/FourthBrain/Midterm/Data/test/test')\n",
    "print(len(images))\n",
    "print(type(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels2 = []\n",
    "for number in pseudo_labels:\n",
    "    pseudo_labels2.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pseudo_labels2))\n",
    "print(type(pseudo_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = number_to_class(pseudo_labels2, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_and_unlabeled = pd.concat([train_csv, new_df])\n",
    "labeled_and_unlabeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files1 = os.listdir('/home/sarah/FourthBrain/Midterm/Data/train/train/')\n",
    "path1 = '/home/sarah/FourthBrain/Midterm/Data/train/train/'\n",
    "files2 = os.listdir('/home/sarah/FourthBrain/Midterm/Data/test/test/')\n",
    "path2 = '/home/sarah/FourthBrain/Midterm/Data/test/test/'\n",
    "dest = '/home/sarah/FourthBrain/Midterm/Data/combined/'\n",
    "\n",
    "for file in files1:\n",
    "    if file.endswith('.jpg'):\n",
    "        shutil.copy2(path1+file, dest)\n",
    "for file in files2:\n",
    "    if file.endswith('.jpg'):\n",
    "        shutil.copy2(path2+file, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['diabetic retinopathy', 'glaucoma', 'normal', 'other']\n",
    "labels_gen = datagen.flow_from_dataframe(directory = './Data/combined',\n",
    "                                        dataframe = labeled_and_unlabeled,\n",
    "                                        x_col = 'filename',\n",
    "                                        y_col = columns,\n",
    "                                        target_size=(224,224),\n",
    "                                        batch_size=15,\n",
    "                                        rescale=1./255,\n",
    "                                        class_mode='other',\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting2 = model.fit_generator(labels_gen,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=100,\n",
    "                    verbose=1, \n",
    "                    validation_data=test_gen,\n",
    "                    validation_steps = 10,\n",
    "                    callbacks=[model_checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_gen)\n",
    "y_true_val = class_to_number(test_csv)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "target_names = ['diabetic retinopathy', 'glaucoma', 'normal', 'other']\n",
    "print(confusion_matrix(y_true_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the fact that my 'improved' training run can now only predict one class, I'm guessing I did something wrong with the self labeling to make the network considerably worse than my already bad original model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
